{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <b>Projekt - </b>\n","## Na przedmiot: _Metody analizy danych_\n","\n","## Użyta metoda analizy danych: \n","\n","<br>\n","\n","Autorzy:\n","- Jakub Zawadzki  217576\n","- Patryk Zawadzki 217565\n","- Paweł Hebda     217626\n","- Marcin Galewski 220252"]},{"cell_type":"markdown","metadata":{},"source":["Ustalenie zmiennych"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["spam\n","['http', 'font', 'td', 'statements', 'www', 'nbsp', 'height', 'pills', 'width', 'size']\n","nie spam\n","['ect', 'hou', 'enron', 'deal', 'gas', 'meter', 'hpl', 'pm', 'please', 'daren']\n"]}],"source":["import pandas as pd\n","import nltk\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","dane = pd.read_csv('spam_ham_dataset.csv')\n","\n","slowa = {}\n","tokenizer = nltk.RegexpTokenizer(pattern='[a-zA-Z]+')\n","stop_words = nltk.corpus.stopwords.words('english')\n","stop_words.extend(['subject','cc'])\n","for i in range(len(dane)):\n","    mail = dane['text'][i]\n","    mail_slowa = tokenizer.tokenize(mail)\n","    if dane['label_num'][i]==0:\n","        for j in range(len(mail_slowa)):\n","            if mail_slowa[j].lower() in slowa and mail_slowa[j].lower() not in stop_words:\n","                slowa[mail_slowa[j].lower()] += 1\n","            else:\n","                slowa[mail_slowa[j].lower()] = 1\n","    if dane['label_num'][i]==1:\n","        for j in range(len(mail_slowa)):\n","            if mail_slowa[j].lower() in slowa and mail_slowa[j].lower() not in stop_words:\n","                slowa[mail_slowa[j].lower()] -= 1\n","            else:\n","                slowa[mail_slowa[j].lower()] = -1\n","\n","posortowane = sorted(slowa.items(), key=lambda x: x[1])\n","spam_slowa = []\n","for i in range(10):\n","    spam_slowa.append(posortowane[i][0])\n","ham_slowa = []\n","for i in range(10):\n","    ham_slowa.append(posortowane[len(posortowane)-1-i][0])\n","print('spam')\n","print(spam_slowa)\n","print('nie spam')\n","print(ham_slowa)"]},{"cell_type":"markdown","metadata":{},"source":["Obliczenie zmiennych"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def find_features(document):\n","    words = set(document)\n","    features = {}\n","    for w in word_features:\n","        features[w] = (w in words)\n","\n","    return features\n","\n","wszystkie_slowa = []\n","for email in dane['text']:\n","    wszystkie_slowa.extend(email.split())\n","\n","freq_dist = nltk.probability.FreqDist(wszystkie_slowa)\n","word_features = list(freq_dist.keys())[:1000]\n","\n","featuresets = [(find_features(text),label) for text,label in dane[['text','label']].itertuples(index=False)]\n","training_set = featuresets[:4000]\n","testing_set = featuresets[4000:]\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Naive Bayes"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classifier accuracy percent: 74.8932536293766\n"]}],"source":["classifier = nltk.NaiveBayesClassifier.train(training_set)\n","print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
